{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "import nltk, re, numpy as np, pandas as pd, collections\n",
        "from nltk.corpus import movie_reviews"
      ],
      "metadata": {
        "id": "SkGHIV6ah89A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('movie_reviews', quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h4qVf4yiqXm",
        "outputId": "9ce83926-1ccf-49e4-a6d4-7d83e5217da9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fileids = movie_reviews.fileids()\n",
        "words = [movie_reviews.words(text_id) for text_id in ids]\n",
        "texts = [' '.join(text) for text in words]\n",
        "labels = np.array([1 if movie_reviews.categories(text_id)[0] == 'pos' else 0 for text_id in ids])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BYa2YfvOi0_9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [re.sub(r\"\\s+\", \" \", d.lower()) for d in texts]"
      ],
      "metadata": {
        "id": "uJv7sXiTjdg2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Loaded {len(docs)} docs – {labels.sum()} pos, {len(labels)-labels.sum()} neg\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTVcZth5jdaO",
        "outputId": "3f5b853d-2be5-41f4-bf27-9ede05f1cdbf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2000 docs – 1000 pos, 1000 neg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#manually define folds for training\n",
        "\n",
        "def fold_id(fid:str)->int:\n",
        "    cv_num = int(re.search(r'cv(\\d{3})_', fid).group(1))\n",
        "    return cv_num % 10\n",
        "fold_idx = np.array([fold_id(fid) for fid in fileids])\n",
        "# Verify balance\n",
        "print(collections.Counter(fold_idx))\n",
        "# Build explicit (train, test) splits list\n",
        "cv_splits = [(np.where(fold_idx!=k)[0], np.where(fold_idx==k)[0]) for k in range(10)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnP2MEUPkq4h",
        "outputId": "64f67092-8dc8-4a6b-80ee-b5a3842c37cd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({np.int64(0): 200, np.int64(1): 200, np.int64(2): 200, np.int64(3): 200, np.int64(4): 200, np.int64(5): 200, np.int64(6): 200, np.int64(7): 200, np.int64(8): 200, np.int64(9): 200})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec_presence = CountVectorizer(binary=True, stop_words=None, ngram_range=(1,1))\n",
        "\n",
        "#Baseline proroduction\n",
        "models = {\n",
        "    'NaiveBayes': MultinomialNB(alpha=1.0),\n",
        "    'MaxEnt'    : LogisticRegression(max_iter=2000, C=1e4, solver='lbfgs'),\n",
        "    'SVM'       : LinearSVC(C=1, max_iter=5000)\n",
        "}\n",
        "\n",
        "baseline_res = {}\n",
        "for name, clf in models.items():\n",
        "    pipe   = Pipeline([('vec', vec_presence), ('clf', clf)])\n",
        "    scores = cross_val_score(pipe, docs, labels, cv=cv_splits, scoring='accuracy', n_jobs=-1)\n",
        "    baseline_res[name] = (scores.mean(), scores.std())\n",
        "    print(f\"{name:10s}  mean={scores.mean():.3f}  std={scores.std():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ga89Z5_DoFcw",
        "outputId": "97da0204-e153-4d0d-f847-3fee4b839792"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaiveBayes  mean=0.821  std=0.034\n",
            "MaxEnt      mean=0.865  std=0.026\n",
            "SVM         mean=0.849  std=0.036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 improvement with english stopwords\n",
        "\n",
        "vec_presence  = CountVectorizer(binary=True, stop_words='english', ngram_range=(1,1))\n",
        "\n",
        "models = {\n",
        "    'NaiveBayes': MultinomialNB(alpha=1.0),\n",
        "    'MaxEnt'    : LogisticRegression(max_iter=2000, C=1e4, solver='lbfgs'),\n",
        "    'SVM'       : LinearSVC(C=1, max_iter=5000)\n",
        "}\n",
        "\n",
        "baseline_res = {}\n",
        "for name, clf in models.items():\n",
        "    pipe   = Pipeline([('vec', vec_presence), ('clf', clf)])\n",
        "    scores = cross_val_score(pipe, docs, labels, cv=cv_splits, scoring='accuracy', n_jobs=-1)\n",
        "    baseline_res[name] = (scores.mean(), scores.std())\n",
        "    print(f\"{name:10s}  mean={scores.mean():.3f}  std={scores.std():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNYXYinWoPrB",
        "outputId": "0a9f48a7-feae-4ecd-917b-774a5fccea64"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaiveBayes  mean=0.822  std=0.032\n",
            "MaxEnt      mean=0.862  std=0.021\n",
            "SVM         mean=0.847  std=0.025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 improvement with english stopwords + TF-IDF\n",
        "\n",
        "vec_presence  = TfidfVectorizer(binary=True, stop_words='english', ngram_range=(1,1))\n",
        "\n",
        "models = {\n",
        "    'NaiveBayes': MultinomialNB(alpha=1.0),\n",
        "    'MaxEnt'    : LogisticRegression(max_iter=2000, C=1e4, solver='lbfgs'),\n",
        "    'SVM'       : LinearSVC(C=1, max_iter=5000)\n",
        "}\n",
        "\n",
        "baseline_res = {}\n",
        "for name, clf in models.items():\n",
        "    pipe   = Pipeline([('vec', vec_presence), ('clf', clf)])\n",
        "    scores = cross_val_score(pipe, docs, labels, cv=cv_splits, scoring='accuracy', n_jobs=-1)\n",
        "    baseline_res[name] = (scores.mean(), scores.std())\n",
        "    print(f\"{name:10s}  mean={scores.mean():.3f}  std={scores.std():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTTSSSxCpMW3",
        "outputId": "e8bb0e4a-e9c8-4be2-b98c-edd16cfc28f4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaiveBayes  mean=0.842  std=0.025\n",
            "MaxEnt      mean=0.879  std=0.019\n",
            "SVM         mean=0.877  std=0.022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3 improvement with english stopwords + TF-IDF + trigrams\n",
        "vec_presence  = TfidfVectorizer(binary=True, stop_words='english', ngram_range=(1,3))\n",
        "\n",
        "models = {\n",
        "    'NaiveBayes': MultinomialNB(alpha=1.0),\n",
        "    'MaxEnt'    : LogisticRegression(max_iter=2000, C=1, solver='lbfgs'),\n",
        "    'SVM'       : LinearSVC(C=10, max_iter=5000)\n",
        "}\n",
        "\n",
        "baseline_res = {}\n",
        "for name, clf in models.items():\n",
        "    pipe   = Pipeline([('vec', vec_presence), ('clf', clf)])\n",
        "    scores = cross_val_score(pipe, docs, labels, cv=cv_splits, scoring='accuracy', n_jobs=-1)\n",
        "    baseline_res[name] = (scores.mean(), scores.std())\n",
        "    print(f\"{name:10s}  mean={scores.mean():.3f}  std={scores.std():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTlpCtqhpinn",
        "outputId": "82e633c6-b111-4248-a4fb-8bf50f5be347"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaiveBayes  mean=0.841  std=0.020\n",
            "MaxEnt      mean=0.847  std=0.028\n",
            "SVM         mean=0.861  std=0.021\n"
          ]
        }
      ]
    }
  ]
}